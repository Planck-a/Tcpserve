[线程池.hpp](https://github.com/Planck-a/Tcpserve/blob/master/code/pThreadpool.hpp)

其基本理念是：先创建一批资源，当有用户到来时，直接分配已创建好的资源，它的主要目的是减少系统在频繁创建资源时的开销

实现原理：主服务线程创建既定数量的服务线程，当有客户端到来时，则从线程池中找出空闲的服务线程，为其服务，服务完毕后，线程不进行释放，重新放回线程池；若当前线程池已满，则将当前的客户端加入等待队列

线程池设计思路：
思路：主线程中创建一个池子，池子中包含了要处理的任务队列，加任务是主线程中进行的。如果队列为空，那么子线程就会调用condition_timedwait()阻塞，同时释放自己的锁，让其他线程访问池子；如果主线程现在有任务要处理，就会调用condition_signal()唤醒其中一个子线程，去处理任务。

如何实现线程池的？
---
使用互斥锁保证对线程池的互斥访问，使用条件变量实现同步。

初始化线程池，创建worker线程。

各worker最外层为while循环，获得互斥锁的线程可以进入线程池，若无task队列为空则 pthread_cond_wait自动解锁互斥量，置该线程为等待状态并等待条件触发。若存在task则取出队列第一个任务，之后立即开锁，之后再并执行具体操作。这里若先执行后开锁则在task完成前整个线程池处于锁定状态，其他线程不能取任务，相当于串行操作！

建立连接后，当客户端请求到达服务器端，创建task任务并添加到线程池task队列尾，当添加完task之后调用pthread_cond_signal唤醒因没有具体task而处于等待状态的worker线程。

`任务列表`
```
typedef struct task
{
    void *(*run)(void *args);//函数指针
    task *pnext;
}task;
```

`线程池设计`
```
typedef Threadpool
{
    condition_t ready;    //状态量，池子的控制权
	task_t *first;       //任务队列中第一个任务
	task_t *last;        //
	int counter;         //线程池中已有线程数
	int idle;            //线程池中空闲的线程数
	int max_threads;     //线程池最大线程数
	int quit;            //是否退出标志
}Threadpool;
```
`线程池加入任务`

 1、将任务加入到任务队列，加入到链表最后位置.
 
 2、判断池子的情况，接收第一个任务时，池子是空的，所以会先创建新线程；之后再有任务，判断，如果有线程闲，则条件变量激活；如果没线程空闲，但是还不到最大线程数，创建新线程
 
产生新任务，加入到队列的尾部
```
condition_lock(&pool->ready);

//线程池中有线程空闲，唤醒
if (pool->idle > 0)
	{
		condition_signal(&pool->ready);
	}
 //虽然没有线程空闲，但是池中线程个数没有达到设定的最大值，可以创建一个新的线性
 else if (pool->counter < pool->max_threads)
	{
		pthread_t tid;
		pthread_create(&tid, NULL, thread_routine, pool);
  //创建新线程，执行thread_routine，参数是pool
		pool->counter++;
	}
	//结束，访问
	condition_unlock(&pool->ready);
```

创建新线程
```
while (1)
{
    condition_lock(&pool->ready);//加锁就表明我在向池子申请任务
    while (池子任务列表为空)
    {
        condition_timedwait();//阻塞，等待被唤醒
        //阻塞时会释放锁，允许其他线程访问，当被唤醒时，自动加锁
    }
    if(队列不为空)
    {
        //取出等待队列最前的任务，移除任务，并执行任务
        //由于任务执行需要消耗时间，先解锁让其他线程访问线程池
        condition_unlock(&pool->ready);
        task->run(args);
        condition_lock(&pool->ready);
        //重新加锁，加锁就表明我在向池子申请任务
    }
}
```

补充：


如何实现线程池同步互斥？
---
处理线程同步互斥问题可以考虑互斥锁、条件变量、读写锁和信号量。本线程池为1:N模型，主线程负责监听并负责添加任务（建立连接 + 创建参数）到线程池中，之后worker线程负责取任务并执行，可供选择的同步策略可以是"互斥锁 + 条件变量"或信号量来完成。

互斥锁 + 条件变量（线程同步）
```
int pthread_mutex_lock(pthread_mutex_t *mptr);
int pthread_mutex_unlock(pthread_mutex_t *mptr);
int pthread_cond_wait(pthread_cond_t *cptr, pthread_mutex_t *mptr);
int pthread_cond_signal(pthread_cond_t *cptr);
信号量（进程、线程同步）
int sem_init(sem_t *sem, int shared, unsigned int value);
int sem_wait(sem_t *sem);
int sem_post(sem_t *sem);
int sem_destory(sem_t *sem);
```
其实信号量初值设为1（二元信号量）时，可以实现互斥锁功能，信号量初值为N时可以实现条件变量功能。不过信号量主要上锁和解锁可以在不同线程，同步操作容易写错，另外，信号量必须先处理同步信号量再用互斥信号量包住临界区，这里写错会发生死锁情况。所以本线程池使用互斥锁 + 条件变量来实现。

```
linux下条件变量 ------>条件变量要和锁一起使用，加线程池的锁意味着持续访问线程池，拿到锁了就可以看线程池中现在是否有任务，如果没有任务，就通过条件变量暂时地释放锁，可以是无等待wait和间隔固定时间等待timewait，等时间间隔到了又会重复拿锁操作。条件变量的本质就是一个暂时的释放锁，而signal和lock本质都是申请加锁。
pthread_mutex_t mutex;
pthread_cond_t pcond;

pthread_mutex_lock(&mutex);
pthread_mutex_unlock(&mutex);

pthread_cond_wait(&pcond,&mutex);

struct timespace *abstime;
pthread_cond_timewait(&pcond,&mutex,abstime); ------>如果很长时间都没有激活，子线程阻塞一定后就退出

pthread_cond_signal(&pcond);//唤醒一个
pthread_cond_broadcast(&pcond);//唤醒所有


windows下条件变量
std::mutex mtx;
conditiona_variable -cv;

std::unique_lock <std::mutex> lck(mtx);//阻塞
_cv.wait(lck);

_cv.notify_one();//唤醒

```

和生产者消费者问题区别？
---
本质上依旧是生产者消费者问题，生产者消费者模型通常是对有界缓冲区进行同步操作，但在WebServer中，如果连接缓冲的大小固定的话，有可能导致新来的连接无法投入缓冲池中导致生产者线程（监听线程）被阻塞。所以目前Task任务通过链式队列实现，但目前也在思考如果因为任务未来得及处理，但连接持续被投入线程池会不会造成溢出问题。
